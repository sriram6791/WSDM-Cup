{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ef7a541",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:19.625003Z",
     "iopub.status.busy": "2025-01-16T16:41:19.624758Z",
     "iopub.status.idle": "2025-01-16T16:41:20.303790Z",
     "shell.execute_reply": "2025-01-16T16:41:20.302953Z"
    },
    "papermill": {
     "duration": 0.685652,
     "end_time": "2025-01-16T16:41:20.305592",
     "exception": false,
     "start_time": "2025-01-16T16:41:19.619940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\n",
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/config.json\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/README.md\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/tokenizer.json\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/tokenizer_config.json\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/model.safetensors\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/special_tokens_map.json\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/.gitattributes\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/tokenizer.model\n",
      "/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1/generation_config.json\n",
      "/kaggle/input/checkpoint9200-gemma2/adapter_model.safetensors\n",
      "/kaggle/input/checkpoint9200-gemma2/trainer_state.json\n",
      "/kaggle/input/checkpoint9200-gemma2/training_args.bin\n",
      "/kaggle/input/checkpoint9200-gemma2/adapter_config.json\n",
      "/kaggle/input/checkpoint9200-gemma2/README.md\n",
      "/kaggle/input/checkpoint9200-gemma2/tokenizer.json\n",
      "/kaggle/input/checkpoint9200-gemma2/tokenizer_config.json\n",
      "/kaggle/input/checkpoint9200-gemma2/scheduler.pt\n",
      "/kaggle/input/checkpoint9200-gemma2/special_tokens_map.json\n",
      "/kaggle/input/checkpoint9200-gemma2/optimizer.pt\n",
      "/kaggle/input/checkpoint9200-gemma2/rng_state.pth\n",
      "/kaggle/input/checkpoint9200-gemma2/tokenizer.model\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/model.safetensors.index.json\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/config.json\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/model-00001-of-00002.safetensors\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/model-00002-of-00002.safetensors\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/tokenizer.json\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/tokenizer_config.json\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/special_tokens_map.json\n",
      "/kaggle/input/0_gemma-2-9b-it-4bit_modified_insp/transformers/inspired/1/tokenizer.model\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model.safetensors.index.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model-00001-of-00002.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/model-00002-of-00002.safetensors\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer_config.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/special_tokens_map.json\n",
      "/kaggle/input/gemma-2/transformers/gemma-2-9b-it-4bit/1/gemma-2-9b-it-4bit/tokenizer.model\n",
      "/kaggle/input/lmsys-wheel-files/peft-0.11.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/transformers-4.42.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/sympy-1.12.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/urllib3-2.2.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tqdm-4.66.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/idna-3.7-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/jinja2-3.1.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/mpmath-1.3.0-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/networkx-3.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/filelock-3.15.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/certifi-2024.7.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/accelerate-0.32.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/packaging-24.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/requests-2.32.3-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/typing_extensions-4.12.2-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/huggingface_hub-0.23.4-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/fsspec-2024.6.1-py3-none-any.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl\n",
      "/kaggle/input/lmsys-wheel-files/tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5a362c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:20.314114Z",
     "iopub.status.busy": "2025-01-16T16:41:20.313748Z",
     "iopub.status.idle": "2025-01-16T16:41:20.316716Z",
     "shell.execute_reply": "2025-01-16T16:41:20.316097Z"
    },
    "papermill": {
     "duration": 0.008409,
     "end_time": "2025-01-16T16:41:20.318035",
     "exception": false,
     "start_time": "2025-01-16T16:41:20.309626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U bitsandbytes\n",
    "# !pip install -U bitsandbytes accelerate\n",
    "# !pip install transformers peft\n",
    "# !pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffb1b612",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:20.325755Z",
     "iopub.status.busy": "2025-01-16T16:41:20.325494Z",
     "iopub.status.idle": "2025-01-16T16:41:28.643618Z",
     "shell.execute_reply": "2025-01-16T16:41:28.642767Z"
    },
    "papermill": {
     "duration": 8.323699,
     "end_time": "2025-01-16T16:41:28.645282",
     "exception": false,
     "start_time": "2025-01-16T16:41:20.321583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /kaggle/input/lmsys-wheel-files\r\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\r\n",
      "Processing /kaggle/input/lmsys-wheel-files/peft-0.11.1-py3-none-any.whl\r\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.34.2)\r\n",
      "Processing /kaggle/input/lmsys-wheel-files/bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\r\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\r\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.4.1+cu121)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\r\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.3)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.3)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.5)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\r\n",
      "Installing collected packages: bitsandbytes, peft\r\n",
      "Successfully installed bitsandbytes-0.43.1 peft-0.11.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers peft accelerate bitsandbytes \\\n",
    "    -U --no-index --find-links /kaggle/input/lmsys-wheel-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0667a2e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:28.654965Z",
     "iopub.status.busy": "2025-01-16T16:41:28.654695Z",
     "iopub.status.idle": "2025-01-16T16:41:42.477270Z",
     "shell.execute_reply": "2025-01-16T16:41:42.476569Z"
    },
    "papermill": {
     "duration": 13.829019,
     "end_time": "2025-01-16T16:41:42.478857",
     "exception": false,
     "start_time": "2025-01-16T16:41:28.649838",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from dataclasses import dataclass\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import Gemma2ForSequenceClassification, GemmaTokenizerFast, BitsAndBytesConfig\n",
    "from transformers.data.data_collator import pad_without_fast_tokenizer_warning\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536b1fd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.488276Z",
     "iopub.status.busy": "2025-01-16T16:41:42.487828Z",
     "iopub.status.idle": "2025-01-16T16:41:42.517423Z",
     "shell.execute_reply": "2025-01-16T16:41:42.516878Z"
    },
    "papermill": {
     "duration": 0.035481,
     "end_time": "2025-01-16T16:41:42.518715",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.483234",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert torch.cuda.device_count() == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56f44f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.527264Z",
     "iopub.status.busy": "2025-01-16T16:41:42.527024Z",
     "iopub.status.idle": "2025-01-16T16:41:42.531153Z",
     "shell.execute_reply": "2025-01-16T16:41:42.530343Z"
    },
    "papermill": {
     "duration": 0.00962,
     "end_time": "2025-01-16T16:41:42.532278",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.522658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Need to change paths here\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    gemma_dir = '/kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1'\n",
    "    lora_dir = '/kaggle/input/checkpoint9200-gemma2'\n",
    "    max_length = 2048\n",
    "    batch_size = 4\n",
    "    device = torch.device(\"cuda\")    \n",
    "    tta = False  # test time augmentation. <prompt>-<model-b's response>-<model-a's response>\n",
    "    spread_max_length = False  # whether to apply max_length//3 on each input or max_length on the concatenated input\n",
    "\n",
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eca2ec5",
   "metadata": {
    "papermill": {
     "duration": 0.003605,
     "end_time": "2025-01-16T16:41:42.539848",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.536243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "913ca194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.548045Z",
     "iopub.status.busy": "2025-01-16T16:41:42.547810Z",
     "iopub.status.idle": "2025-01-16T16:41:42.687889Z",
     "shell.execute_reply": "2025-01-16T16:41:42.687010Z"
    },
    "papermill": {
     "duration": 0.145696,
     "end_time": "2025-01-16T16:41:42.689271",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.543575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ffe262",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.698064Z",
     "iopub.status.busy": "2025-01-16T16:41:42.697840Z",
     "iopub.status.idle": "2025-01-16T16:41:42.714793Z",
     "shell.execute_reply": "2025-01-16T16:41:42.713980Z"
    },
    "papermill": {
     "duration": 0.02277,
     "end_time": "2025-01-16T16:41:42.716080",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.693310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>scored</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327228</td>\n",
       "      <td>Caso Clínico: Un hombre de 70 años con anteced...</td>\n",
       "      <td>**Diagnóstico Diferencial de Anemia en Pacient...</td>\n",
       "      <td>Basándonos en el caso clínico presentado, pode...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139415</td>\n",
       "      <td>Peel Company received a cash dividend from a c...</td>\n",
       "      <td>The correct answer is **(a) No No**. Here's wh...</td>\n",
       "      <td>The correct answer is **(a) No No**. Here's wh...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235630</td>\n",
       "      <td>Há um grave problema com o relógio da torre da...</td>\n",
       "      <td>Dois problemas interessantes! **Problema 1: O ...</td>\n",
       "      <td>Vamos resolver os dois problemas em sequência....</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                             prompt  \\\n",
       "0   327228  Caso Clínico: Un hombre de 70 años con anteced...   \n",
       "1  1139415  Peel Company received a cash dividend from a c...   \n",
       "2  1235630  Há um grave problema com o relógio da torre da...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  **Diagnóstico Diferencial de Anemia en Pacient...   \n",
       "1  The correct answer is **(a) No No**. Here's wh...   \n",
       "2  Dois problemas interessantes! **Problema 1: O ...   \n",
       "\n",
       "                                          response_b  scored  \n",
       "0  Basándonos en el caso clínico presentado, pode...   False  \n",
       "1  The correct answer is **(a) No No**. Here's wh...   False  \n",
       "2  Vamos resolver os dois problemas em sequência....   False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def process_text(text: str) -> str:\n",
    "    # Safely replace \"null\" with an empty string and remove extra spaces\n",
    "    return \" \".join(str(text).replace(\"null\", \"\").split())\n",
    "\n",
    "# Apply the function to the DataFrame columns\n",
    "test.loc[:, 'prompt'] = test['prompt'].apply(process_text)\n",
    "test.loc[:, 'response_a'] = test['response_a'].apply(process_text)\n",
    "test.loc[:, 'response_b'] = test['response_b'].apply(process_text)\n",
    "\n",
    "# Display the first 5 rows\n",
    "display(test.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15510918",
   "metadata": {
    "papermill": {
     "duration": 0.003811,
     "end_time": "2025-01-16T16:41:42.723982",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.720171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9b84a57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.732640Z",
     "iopub.status.busy": "2025-01-16T16:41:42.732431Z",
     "iopub.status.idle": "2025-01-16T16:41:42.737841Z",
     "shell.execute_reply": "2025-01-16T16:41:42.737121Z"
    },
    "papermill": {
     "duration": 0.011012,
     "end_time": "2025-01-16T16:41:42.738989",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.727977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize(\n",
    "    tokenizer, prompt, response_a, response_b, max_length=cfg.max_length, spread_max_length=cfg.spread_max_length\n",
    "):\n",
    "    prompt = [\"<Task>:Which response is better? which response will be preffered by user for given prompt? if response_a is better output model_a , if response_b is better output model_b in only one word,<prompt>: \" + p for p in prompt]\n",
    "    response_a = [\"\\n\\n<response_a>: \" + r_a for r_a in response_a]\n",
    "    response_b = [\"\\n\\n<response_b>: \" + r_b for r_b in response_b]\n",
    "    if spread_max_length:\n",
    "        prompt = tokenizer(prompt, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_a = tokenizer(response_a, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        response_b = tokenizer(response_b, max_length=max_length//3, truncation=True, padding=False).input_ids\n",
    "        input_ids = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        attention_mask = [[1]* len(i) for i in input_ids]\n",
    "    else:\n",
    "        text = [p + r_a + r_b for p, r_a, r_b in zip(prompt, response_a, response_b)]\n",
    "        tokenized = tokenizer(text, max_length=max_length, truncation=True, padding=False)\n",
    "        input_ids = tokenized.input_ids\n",
    "        attention_mask = tokenized.attention_mask\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd75e2b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:42.747526Z",
     "iopub.status.busy": "2025-01-16T16:41:42.747309Z",
     "iopub.status.idle": "2025-01-16T16:41:43.633291Z",
     "shell.execute_reply": "2025-01-16T16:41:43.632365Z"
    },
    "papermill": {
     "duration": 0.891825,
     "end_time": "2025-01-16T16:41:43.634753",
     "exception": false,
     "start_time": "2025-01-16T16:41:42.742928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 651 ms, sys: 164 ms, total: 815 ms\n",
      "Wall time: 881 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tokenizer = GemmaTokenizerFast.from_pretrained(cfg.gemma_dir)\n",
    "tokenizer.add_eos_token = True\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "data = pd.DataFrame()\n",
    "data[\"id\"] = test[\"id\"]\n",
    "data[\"input_ids\"], data[\"attention_mask\"] = tokenize(tokenizer, test[\"prompt\"], test[\"response_a\"], test[\"response_b\"])\n",
    "data[\"length\"] = data[\"input_ids\"].apply(len)\n",
    "\n",
    "aug_data = pd.DataFrame()\n",
    "aug_data[\"id\"] = test[\"id\"]\n",
    "# swap response_a & response_b\n",
    "aug_data['input_ids'], aug_data['attention_mask'] = tokenize(tokenizer, test[\"prompt\"], test[\"response_b\"], test[\"response_a\"])\n",
    "aug_data[\"length\"] = aug_data[\"input_ids\"].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "238a96f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:43.644198Z",
     "iopub.status.busy": "2025-01-16T16:41:43.643967Z",
     "iopub.status.idle": "2025-01-16T16:41:43.658441Z",
     "shell.execute_reply": "2025-01-16T16:41:43.657594Z"
    },
    "papermill": {
     "duration": 0.020388,
     "end_time": "2025-01-16T16:41:43.659582",
     "exception": false,
     "start_time": "2025-01-16T16:41:43.639194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><Task>:Which response is better? which response will be preffered by user for given prompt? if response_a is better output model_a , if response_b is better output model_b in only one word,<prompt>: Caso Clínico: Un hombre de 70 años con antecedentes de cáncer testicular tratado en 1990 y cáncer gástrico tratado en 2020, es diagnosticado con leucemia mieloide aguda (LMA). El paciente inicia tratamiento con quimioterapia (12 sesiones planificadas) y se presenta en la consulta después de la primera sesión con síntomas de fatiga intensa, disnea leve, palpitaciones y mareos. Los estudios de laboratorio revelan una hemoglobina de 8 g/dL, leucocitos bajos, y plaquetas en el límite inferior de lo normal. El paciente refiere no haber tenido sangrados visibles, pero menciona sentirse más cansado de lo habitual desde el inicio del tratamiento. No tiene fiebre ni signos de infección activa. Pregunta: Con base en el cuadro clínico descrito, proponga un diagnóstico diferencial que incluya al menos tres posibles causas de la anemia en este paciente.\n",
      "\n",
      "<response_a>: **Diagnóstico Diferencial de Anemia en Paciente con Leucemia Mieloide Aguda (LMA)** **Antecedentes** * Paciente de 70 años con antecedentes de cáncer testicular tratado en 1990 y cáncer gástrico tratado en 2020. * Diagnóstico de Leucemia Mieloide Aguda (LMA) y tratamiento con quimioterapia. * Síntomas de fatiga intensa, disnea leve, palpitaciones y mareos después de la primera sesión de quimioterapia. **Hallazgos Clínicos** * Hemoglobina (Hb) de 8 g/dL. * Leucocitos bajos. * Plaquetas en el límite inferior de lo normal. * No hay sangrados visibles, pero el paciente se siente más cansado de lo habitual. **Diagnóstico Diferencial de la Anemia** Considerando la situación clínica del paciente, se presentan tres posibles causas de anemia: ### 1. **Anemia Inducida por Quimioterapia** La quimioterapia puede causar anemia debido a la destrucción de células sanguíneas en el hueso óseo. La quimioterapia puede afectar la producción de glóbulos rojos, blancos y plaquetas, lo que lleva a una anemia. ### 2. **Anemia de Desfalcación** La anemia de desfalcación es una condición en la que la producción de glóbulos rojos es insuficiente debido a una falta de hierro en el cuerpo. La anemia de desfalcación es más común en personas que tienen antecedentes de cáncer y han recibido quimioterapia. ### 3. **Anemia de Sobrecarga de Ferropén** La anemia de sobrecarga de ferropén se produce cuando hay un exceso de ferropén en el cuerpo, lo que impide que el cuerpo absorba el hierro de la dieta. La quimioterapia puede causar un mayor exceso de ferropén en el cuerpo, lo que lleva a esta condición. **Conclusión** En resumen, la anemia en el paciente con LMA puede estar causada por tres posibles factores: anemia inducida por quimioterapia, anemia de desfalcación y anemia de sobrecarga de ferropén. Es importante realizar más pruebas de laboratorio y estudios para determinar la causa específica de la anemia y llevar a cabo el tratamiento adecuado.\n",
      "\n",
      "<response_b>: Basándonos en el caso clínico presentado, podemos proponer un diagnóstico diferencial que incluye varias posibles causas de la anemia en este paciente de 70 años con leucemia mieloide aguda (LMA) y antecedentes de cáncer testicular y cáncer gástrico. Las posibles causas de la anemia incluyen: 1. **Anemia debida a la leucemia mieloide aguda (LMA)**: - La LMA puede afectar directamente la producción de glóbulos rojos en la médula ósea, lo que resulta en anemia. La presencia de células leucémicas en la médula ósea puede desplazar a las células normales, incluyendo las precursoras de los glóbulos rojos (eritrocitos). - La anemia en este contexto puede ser tanto consecuencia de la enfermedad subyacente como un efecto secundario de la quimioterapia. 2. **Anemia por déficit de hierro**: - Aunque el paciente no menciona sangrado visible, la anemia por déficit de hierro puede ocurrir debido a la pérdida crónica de hierro que puede pasar desapercibida. Esto podría ser resultado de pequeñas pérdidas de sangre internas, posiblemente relacionadas con la enfermedad gástrica previa. - La quimioterapia también puede aumentar la demanda de hierro y reducir su absorción, contribuyendo a la anemia. 3. **Anemia aplásica o hipoproliferativa secundaria a quimioterapia**: - La quimioterapia puede dañar la médula ósea, inhibiendo la producción de todas las células sanguíneas, incluyendo los glóbulos rojos. Esto resulta en una disminución generalizada de los componentes sanguíneos, conocida como anemia aplásica o hipoproliferativa. - La disminución de los leucocitos y las plaquetas también apoya esta posibilidad, ya que indica un daño generalizado en la médula ósea. 4. **Anemia por hemólisis**: - Aunque menos probable en este contexto, la anemia por hemólisis (destrucción acelerada de los glóbulos rojos) puede ocurrir en algunos casos de LMA, especialmente si hay complicaciones inmunológicas o autoinmunes. - La presencia de anticuerpos contra los glóbulos rojos o factores de coagulación alterados pueden llevar a la hemólisis. 5. **Anemia por deficiencia de vitamina B12 o ácido fólico**: - Aunque menos común en pacientes con cáncer, la deficiencia de vitamina B12 o ácido fólico puede contribuir a la anemia, especialmente si hay problemas de absorción debido a la enfermedad gástrica previa. - Estos déficits pueden ser exacerbados por la quimioterapia, que puede afectar la absorción intestinal. Para confirmar el diagnóstico y determinar la causa exacta de la anemia, sería necesario realizar los siguientes estudios adicionales: - **Hemograma completo**: Para evaluar más detalladamente los recuentos de glóbulos rojos, leucocitos y plaquetas. - **Pruebas de función renal y hepática**: Para descartar cualquier alteración que pueda afectar la producción de eritropoyetina. - **Pruebas de hierro sérico, ferritina y proteína C reactiva**: Para evaluar la presencia de deficiencia de hierro y signos de inflamación. - **Niveles de vitamina B12 y ácido fólico**: Para descartar deficiencias nutricionales. - **Pruebas de hemólisis**: Como lactato deshidrogenasa (LDH), bilirrubina indirecta y reticulocitos. - **Biopsia de médula ósea**: Para evaluar la morfología celular y confirmar el diagnóstico de LMA, así como descartar otras enfermedades hematológicas. Estos estudios ayudarán a definir el diagnóstico preciso y guiarán el manejo adecuado del paciente.<eos>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a33e4f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:43.668808Z",
     "iopub.status.busy": "2025-01-16T16:41:43.668575Z",
     "iopub.status.idle": "2025-01-16T16:41:43.682269Z",
     "shell.execute_reply": "2025-01-16T16:41:43.681382Z"
    },
    "papermill": {
     "duration": 0.019593,
     "end_time": "2025-01-16T16:41:43.683548",
     "exception": false,
     "start_time": "2025-01-16T16:41:43.663955",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bos><Task>:Which response is better? which response will be preffered by user for given prompt? if response_a is better output model_a , if response_b is better output model_b in only one word,<prompt>: Caso Clínico: Un hombre de 70 años con antecedentes de cáncer testicular tratado en 1990 y cáncer gástrico tratado en 2020, es diagnosticado con leucemia mieloide aguda (LMA). El paciente inicia tratamiento con quimioterapia (12 sesiones planificadas) y se presenta en la consulta después de la primera sesión con síntomas de fatiga intensa, disnea leve, palpitaciones y mareos. Los estudios de laboratorio revelan una hemoglobina de 8 g/dL, leucocitos bajos, y plaquetas en el límite inferior de lo normal. El paciente refiere no haber tenido sangrados visibles, pero menciona sentirse más cansado de lo habitual desde el inicio del tratamiento. No tiene fiebre ni signos de infección activa. Pregunta: Con base en el cuadro clínico descrito, proponga un diagnóstico diferencial que incluya al menos tres posibles causas de la anemia en este paciente.\n",
      "\n",
      "<response_a>: Basándonos en el caso clínico presentado, podemos proponer un diagnóstico diferencial que incluye varias posibles causas de la anemia en este paciente de 70 años con leucemia mieloide aguda (LMA) y antecedentes de cáncer testicular y cáncer gástrico. Las posibles causas de la anemia incluyen: 1. **Anemia debida a la leucemia mieloide aguda (LMA)**: - La LMA puede afectar directamente la producción de glóbulos rojos en la médula ósea, lo que resulta en anemia. La presencia de células leucémicas en la médula ósea puede desplazar a las células normales, incluyendo las precursoras de los glóbulos rojos (eritrocitos). - La anemia en este contexto puede ser tanto consecuencia de la enfermedad subyacente como un efecto secundario de la quimioterapia. 2. **Anemia por déficit de hierro**: - Aunque el paciente no menciona sangrado visible, la anemia por déficit de hierro puede ocurrir debido a la pérdida crónica de hierro que puede pasar desapercibida. Esto podría ser resultado de pequeñas pérdidas de sangre internas, posiblemente relacionadas con la enfermedad gástrica previa. - La quimioterapia también puede aumentar la demanda de hierro y reducir su absorción, contribuyendo a la anemia. 3. **Anemia aplásica o hipoproliferativa secundaria a quimioterapia**: - La quimioterapia puede dañar la médula ósea, inhibiendo la producción de todas las células sanguíneas, incluyendo los glóbulos rojos. Esto resulta en una disminución generalizada de los componentes sanguíneos, conocida como anemia aplásica o hipoproliferativa. - La disminución de los leucocitos y las plaquetas también apoya esta posibilidad, ya que indica un daño generalizado en la médula ósea. 4. **Anemia por hemólisis**: - Aunque menos probable en este contexto, la anemia por hemólisis (destrucción acelerada de los glóbulos rojos) puede ocurrir en algunos casos de LMA, especialmente si hay complicaciones inmunológicas o autoinmunes. - La presencia de anticuerpos contra los glóbulos rojos o factores de coagulación alterados pueden llevar a la hemólisis. 5. **Anemia por deficiencia de vitamina B12 o ácido fólico**: - Aunque menos común en pacientes con cáncer, la deficiencia de vitamina B12 o ácido fólico puede contribuir a la anemia, especialmente si hay problemas de absorción debido a la enfermedad gástrica previa. - Estos déficits pueden ser exacerbados por la quimioterapia, que puede afectar la absorción intestinal. Para confirmar el diagnóstico y determinar la causa exacta de la anemia, sería necesario realizar los siguientes estudios adicionales: - **Hemograma completo**: Para evaluar más detalladamente los recuentos de glóbulos rojos, leucocitos y plaquetas. - **Pruebas de función renal y hepática**: Para descartar cualquier alteración que pueda afectar la producción de eritropoyetina. - **Pruebas de hierro sérico, ferritina y proteína C reactiva**: Para evaluar la presencia de deficiencia de hierro y signos de inflamación. - **Niveles de vitamina B12 y ácido fólico**: Para descartar deficiencias nutricionales. - **Pruebas de hemólisis**: Como lactato deshidrogenasa (LDH), bilirrubina indirecta y reticulocitos. - **Biopsia de médula ósea**: Para evaluar la morfología celular y confirmar el diagnóstico de LMA, así como descartar otras enfermedades hematológicas. Estos estudios ayudarán a definir el diagnóstico preciso y guiarán el manejo adecuado del paciente.\n",
      "\n",
      "<response_b>: **Diagnóstico Diferencial de Anemia en Paciente con Leucemia Mieloide Aguda (LMA)** **Antecedentes** * Paciente de 70 años con antecedentes de cáncer testicular tratado en 1990 y cáncer gástrico tratado en 2020. * Diagnóstico de Leucemia Mieloide Aguda (LMA) y tratamiento con quimioterapia. * Síntomas de fatiga intensa, disnea leve, palpitaciones y mareos después de la primera sesión de quimioterapia. **Hallazgos Clínicos** * Hemoglobina (Hb) de 8 g/dL. * Leucocitos bajos. * Plaquetas en el límite inferior de lo normal. * No hay sangrados visibles, pero el paciente se siente más cansado de lo habitual. **Diagnóstico Diferencial de la Anemia** Considerando la situación clínica del paciente, se presentan tres posibles causas de anemia: ### 1. **Anemia Inducida por Quimioterapia** La quimioterapia puede causar anemia debido a la destrucción de células sanguíneas en el hueso óseo. La quimioterapia puede afectar la producción de glóbulos rojos, blancos y plaquetas, lo que lleva a una anemia. ### 2. **Anemia de Desfalcación** La anemia de desfalcación es una condición en la que la producción de glóbulos rojos es insuficiente debido a una falta de hierro en el cuerpo. La anemia de desfalcación es más común en personas que tienen antecedentes de cáncer y han recibido quimioterapia. ### 3. **Anemia de Sobrecarga de Ferropén** La anemia de sobrecarga de ferropén se produce cuando hay un exceso de ferropén en el cuerpo, lo que impide que el cuerpo absorba el hierro de la dieta. La quimioterapia puede causar un mayor exceso de ferropén en el cuerpo, lo que lleva a esta condición. **Conclusión** En resumen, la anemia en el paciente con LMA puede estar causada por tres posibles factores: anemia inducida por quimioterapia, anemia de desfalcación y anemia de sobrecarga de ferropén. Es importante realizar más pruebas de laboratorio y estudios para determinar la causa específica de la anemia y llevar a cabo el tratamiento adecuado.<eos>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(aug_data[\"input_ids\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bf6b413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:41:43.693072Z",
     "iopub.status.busy": "2025-01-16T16:41:43.692829Z",
     "iopub.status.idle": "2025-01-16T16:42:24.941121Z",
     "shell.execute_reply": "2025-01-16T16:42:24.940150Z"
    },
    "papermill": {
     "duration": 41.254821,
     "end_time": "2025-01-16T16:42:24.942653",
     "exception": false,
     "start_time": "2025-01-16T16:41:43.687832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Unused kwargs: ['_load_in_4bit', '_load_in_8bit', 'quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
      "Some weights of Gemma2ForSequenceClassification were not initialized from the model checkpoint at /kaggle/input/gemma-2-9b-it-bnb-4bit_hf/transformers/original/1 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load base model on GPU 0\n",
    "device_0 = torch.device('cuda:0')\n",
    "model_0 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_0,\n",
    "    use_cache=False,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Load base model on GPU 1\n",
    "device_1 = torch.device('cuda:1')\n",
    "model_1 = Gemma2ForSequenceClassification.from_pretrained(\n",
    "    cfg.gemma_dir,\n",
    "    device_map=device_1,\n",
    "    use_cache=False,\n",
    "    ignore_mismatched_sizes=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c41c8cec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:42:24.954391Z",
     "iopub.status.busy": "2025-01-16T16:42:24.954140Z",
     "iopub.status.idle": "2025-01-16T16:42:29.105445Z",
     "shell.execute_reply": "2025-01-16T16:42:29.104758Z"
    },
    "papermill": {
     "duration": 4.159121,
     "end_time": "2025-01-16T16:42:29.106931",
     "exception": false,
     "start_time": "2025-01-16T16:42:24.947810",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_0 = PeftModel.from_pretrained(model_0, cfg.lora_dir)\n",
    "model_1 = PeftModel.from_pretrained(model_1, cfg.lora_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a193c43f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:42:29.117381Z",
     "iopub.status.busy": "2025-01-16T16:42:29.117141Z",
     "iopub.status.idle": "2025-01-16T16:42:33.332931Z",
     "shell.execute_reply": "2025-01-16T16:42:33.331696Z"
    },
    "papermill": {
     "duration": 4.222566,
     "end_time": "2025-01-16T16:42:33.334415",
     "exception": false,
     "start_time": "2025-01-16T16:42:29.111849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-9623053eeb8c>:2: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4.200034856796265\n"
     ]
    }
   ],
   "source": [
    "@torch.no_grad()\n",
    "@torch.cuda.amp.autocast()\n",
    "def inference(df, model, batch_size=cfg.batch_size, max_length=cfg.max_length):\n",
    "    \"\"\"\n",
    "    Perform inference on a DataFrame with a given model.\n",
    "    \"\"\"\n",
    "    a_win, b_win = [], []\n",
    "    \n",
    "    for start_idx in range(0, len(df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(df))\n",
    "        tmp = df.iloc[start_idx:end_idx]\n",
    "        input_ids = tmp[\"input_ids\"].to_list()\n",
    "        attention_mask = tmp[\"attention_mask\"].to_list()\n",
    "        \n",
    "        inputs = pad_without_fast_tokenizer_warning(\n",
    "            tokenizer,\n",
    "            {\"input_ids\": input_ids, \"attention_mask\": attention_mask},\n",
    "            padding=\"longest\",\n",
    "            pad_to_multiple_of=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        inputs = {k: v.to(model.device) for k, v in inputs.items()}  # Move inputs to model's device\n",
    "        outputs = model(**inputs)\n",
    "        proba = outputs.logits.softmax(-1).cpu()  # Get probabilities\n",
    "        \n",
    "        a_win.extend(proba[:, 0].tolist())  # Probability for model_a\n",
    "        b_win.extend(proba[:, 1].tolist())  # Probability for model_b\n",
    "    \n",
    "    df[\"winner_model_a\"] = a_win\n",
    "    df[\"winner_model_b\"] = b_win\n",
    "    return df\n",
    "\n",
    "# Sort data by input length\n",
    "data = data.sort_values(\"length\", ascending=False)\n",
    "\n",
    "# Split data into two subsets for parallel processing\n",
    "sub_1 = data.iloc[0::2].copy()\n",
    "sub_2 = data.iloc[1::2].copy()\n",
    "\n",
    "# Perform parallel inference\n",
    "st = time.time()\n",
    "with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "    results = executor.map(inference, (sub_1, sub_2), (model_0, model_1))\n",
    "\n",
    "# Combine the results\n",
    "result_df = pd.concat(results, axis=0)\n",
    "proba = result_df[[\"winner_model_a\", \"winner_model_b\"]].values  # Get probabilities\n",
    "\n",
    "print(f\"Elapsed time: {time.time() - st}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31583ebf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-16T16:42:33.346421Z",
     "iopub.status.busy": "2025-01-16T16:42:33.346165Z",
     "iopub.status.idle": "2025-01-16T16:42:33.361388Z",
     "shell.execute_reply": "2025-01-16T16:42:33.360288Z"
    },
    "papermill": {
     "duration": 0.022801,
     "end_time": "2025-01-16T16:42:33.362762",
     "exception": false,
     "start_time": "2025-01-16T16:42:33.339961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-5237012c58dc>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  submission_df[\"winner_model\"] = submission_df.apply(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327228</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139415</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235630</td>\n",
       "      <td>model_b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id winner_model\n",
       "0   327228      model_b\n",
       "1  1139415      model_a\n",
       "2  1235630      model_b"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully completed inference\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'proba' contains only two columns for 'winner_model_a' and 'winner_model_b'\n",
    "result_df.loc[:, \"winner_model_a\"] = proba[:, 0]  # Probability for model_a winning\n",
    "result_df.loc[:, \"winner_model_b\"] = proba[:, 1]  # Probability for model_b winning\n",
    "\n",
    "# Create the submission DataFrame with the necessary columns\n",
    "submission_df = result_df[[\"id\", 'winner_model_a', 'winner_model_b']]\n",
    "\n",
    "submission_df[\"winner_model\"] = submission_df.apply(\n",
    "    lambda row: \"model_a\" if row[\"winner_model_a\"] > row[\"winner_model_b\"] else \"model_b\", axis=1\n",
    ")\n",
    "\n",
    "submission_df= submission_df.drop(['winner_model_a','winner_model_b'],axis=1)\n",
    "\n",
    "# Save to CSV and display\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "display(submission_df)\n",
    "print(\"Successfully completed inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052f438",
   "metadata": {
    "papermill": {
     "duration": 0.004541,
     "end_time": "2025-01-16T16:42:33.372345",
     "exception": false,
     "start_time": "2025-01-16T16:42:33.367804",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "datasetId": 5297895,
     "sourceId": 8897601,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6488442,
     "sourceId": 10478887,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 86587,
     "modelInstanceId": 63082,
     "sourceId": 75103,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 219483,
     "modelInstanceId": 197659,
     "sourceId": 231742,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 219719,
     "modelInstanceId": 197899,
     "sourceId": 232003,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 78.757334,
   "end_time": "2025-01-16T16:42:36.183661",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-16T16:41:17.426327",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
