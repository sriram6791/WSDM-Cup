{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:26:43.036751Z",
     "iopub.status.busy": "2025-01-09T22:26:43.036090Z",
     "iopub.status.idle": "2025-01-09T22:28:17.830903Z",
     "shell.execute_reply": "2025-01-09T22:28:17.829076Z",
     "shell.execute_reply.started": "2025-01-09T22:26:43.036708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tf-keras 2.16.0 requires tensorflow<2.17,>=2.16, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp tensorflow-text\n",
    "!pip install -q -U tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:17.832289Z",
     "iopub.status.busy": "2025-01-09T22:28:17.832028Z",
     "iopub.status.idle": "2025-01-09T22:28:27.086088Z",
     "shell.execute_reply": "2025-01-09T22:28:27.084404Z",
     "shell.execute_reply.started": "2025-01-09T22:28:17.832263Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1736461703.177160      10 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: === \n",
      "learning/45eac/tfrc/runtime/common_lib.cc:479\n",
      "E0109 22:28:23.209034546      10 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2025-01-09T22:28:23.209016143+00:00\"}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Keras is a high level multi-framework deeplearning API designed for simplicity and ease of use,Using keras 3 you can run workflows on one of the three backends: Tensorflow ,Jax or pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:27.087443Z",
     "iopub.status.busy": "2025-01-09T22:28:27.087064Z",
     "iopub.status.idle": "2025-01-09T22:28:27.092084Z",
     "shell.execute_reply": "2025-01-09T22:28:27.090699Z",
     "shell.execute_reply.started": "2025-01-09T22:28:27.087416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install dependencies<br>\n",
    "Install Keras, KerasNLP, and other dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:27.093224Z",
     "iopub.status.busy": "2025-01-09T22:28:27.092907Z",
     "iopub.status.idle": "2025-01-09T22:28:38.790819Z",
     "shell.execute_reply": "2025-01-09T22:28:38.789039Z",
     "shell.execute_reply.started": "2025-01-09T22:28:27.093198Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Distribute: https://keras.io/guides/distribution/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:38.792022Z",
     "iopub.status.busy": "2025-01-09T22:28:38.791573Z",
     "iopub.status.idle": "2025-01-09T22:28:38.796326Z",
     "shell.execute_reply": "2025-01-09T22:28:38.795048Z",
     "shell.execute_reply.started": "2025-01-09T22:28:38.791997Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## !! Creating a device mesh with (1, number of devices) so that weights are sharded across\n",
    "## CHANGE HERE FOR TPU 1\n",
    "device_mesh = keras.distribution.DeviceMesh(\n",
    "    (1,8),\n",
    "    [\"batch\",\"model\"],\n",
    "    devices = keras.distribution.list_devices(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:38.797589Z",
     "iopub.status.busy": "2025-01-09T22:28:38.797381Z",
     "iopub.status.idle": "2025-01-09T22:28:38.826103Z",
     "shell.execute_reply": "2025-01-09T22:28:38.825047Z",
     "shell.execute_reply.started": "2025-01-09T22:28:38.797568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_dim = \"model\"\n",
    "\n",
    "layout_map = keras.distribution.LayoutMap(device_mesh)\n",
    "layout_map[\"token_embedding/embeddings\"] = (model_dim,None)\n",
    "\n",
    "layout_map[\"decoder_block.*attenetion.*(query|key|value)/kernel\"] = (model_dim,None,None)\n",
    "layout_map[\"decoder_block.*attention_output/kernel\"]= (model_dim,None,None)\n",
    "layout_map[\"decoder_block.*ffw_gating.*/kernel\"] = (None,model_dim)\n",
    "layout_map[\"decoder_block.*ffw_linear/kernel\"] = (model_dim,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:38.827439Z",
     "iopub.status.busy": "2025-01-09T22:28:38.827238Z",
     "iopub.status.idle": "2025-01-09T22:28:38.840129Z",
     "shell.execute_reply": "2025-01-09T22:28:38.839273Z",
     "shell.execute_reply.started": "2025-01-09T22:28:38.827418Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def remove_surrogates(text):\n",
    "    return ''.join(char for char in text if not (0xD800 <= ord(char) <= 0xDFFF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:38.841667Z",
     "iopub.status.busy": "2025-01-09T22:28:38.841446Z",
     "iopub.status.idle": "2025-01-09T22:28:41.273497Z",
     "shell.execute_reply": "2025-01-09T22:28:41.271885Z",
     "shell.execute_reply.started": "2025-01-09T22:28:38.841647Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "input_columns = ['prompt' , 'response_a','response_b']\n",
    "label_columns = ['winner_model_a','winner_model_b']\n",
    "\n",
    "raw_train_dataset = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:41.274587Z",
     "iopub.status.busy": "2025-01-09T22:28:41.274350Z",
     "iopub.status.idle": "2025-01-09T22:28:41.297483Z",
     "shell.execute_reply": "2025-01-09T22:28:41.295912Z",
     "shell.execute_reply.started": "2025-01-09T22:28:41.274564Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n",
       "      <td>vieš po Slovensky?</td>\n",
       "      <td>Áno, hovorím po slovensky. Ako vám môžem pomôcť?</td>\n",
       "      <td>Áno, veď som tu! Môžem ti pomôcť s otázkami al...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Slovak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003800d510e38803efba5ceaec122bc66408fe367b0be...</td>\n",
       "      <td>Dört basamaklı, rakamları birbirinden ve sıfır...</td>\n",
       "      <td>Bu soruyu çözmek için, verilen koşulları adım ...</td>\n",
       "      <td>Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>Turkish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00072026c68f5418ef2da238394e418ce72a534b9b22d5...</td>\n",
       "      <td>현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...</td>\n",
       "      <td>죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...</td>\n",
       "      <td>현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...</td>\n",
       "      <td>Please be boring</td>\n",
       "      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n",
       "      <td>Understood. Here is a straightforward, unadorn...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>reka-flash-20240722</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n",
       "1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "2  0003800d510e38803efba5ceaec122bc66408fe367b0be...   \n",
       "3  00072026c68f5418ef2da238394e418ce72a534b9b22d5...   \n",
       "4  0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                 vieš po Slovensky?   \n",
       "1  You will be given a piece of news. Analyze it ...   \n",
       "2  Dört basamaklı, rakamları birbirinden ve sıfır...   \n",
       "3  현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...   \n",
       "4                                  Please be boring    \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Áno, hovorím po slovensky. Ako vám môžem pomôcť?   \n",
       "1  Let's break down the news and analyze it accor...   \n",
       "2  Bu soruyu çözmek için, verilen koşulları adım ...   \n",
       "3  죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...   \n",
       "4  Alright, I'll be as boring as possible.\\n\\nTod...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0  Áno, veď som tu! Môžem ti pomôcť s otázkami al...  model_a   \n",
       "1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n",
       "2  Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...  model_a   \n",
       "3  현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...  model_b   \n",
       "4  Understood. Here is a straightforward, unadorn...  model_a   \n",
       "\n",
       "               model_a                          model_b language  \n",
       "0           o1-preview               reka-core-20240904   Slovak  \n",
       "1       gemma-2-27b-it             gemini-1.5-flash-002  Russian  \n",
       "2   gpt-4-0125-preview       claude-3-5-sonnet-20240620  Turkish  \n",
       "3        gemma-2-2b-it  llama-3.1-nemotron-70b-instruct  English  \n",
       "4  reka-flash-20240722                grok-2-2024-08-13  English  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:41.298738Z",
     "iopub.status.busy": "2025-01-09T22:28:41.298500Z",
     "iopub.status.idle": "2025-01-09T22:28:51.249473Z",
     "shell.execute_reply": "2025-01-09T22:28:51.248344Z",
     "shell.execute_reply.started": "2025-01-09T22:28:41.298715Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def to_onehot(row):\n",
    "    # Return the row with new columns added\n",
    "    return pd.Series({\n",
    "        \"winner_model_a\": 1 if row['winner'] == \"model_a\" else 0,\n",
    "        \"winner_model_b\": 1 if row['winner'] == \"model_b\" else 0\n",
    "    })\n",
    "\n",
    "# Apply and add new columns\n",
    "onehot_encoded = raw_train_dataset.apply(to_onehot, axis=1)\n",
    "\n",
    "# Add the one-hot encoded columns to the original DataFrame\n",
    "raw_train_dataset = pd.concat([raw_train_dataset, onehot_encoded], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:51.250965Z",
     "iopub.status.busy": "2025-01-09T22:28:51.250722Z",
     "iopub.status.idle": "2025-01-09T22:28:51.263003Z",
     "shell.execute_reply": "2025-01-09T22:28:51.262059Z",
     "shell.execute_reply.started": "2025-01-09T22:28:51.250941Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>language</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00007cff95d7f7974642a785aca248b0f26e60d3312fac...</td>\n",
       "      <td>vieš po Slovensky?</td>\n",
       "      <td>Áno, hovorím po slovensky. Ako vám môžem pomôcť?</td>\n",
       "      <td>Áno, veď som tu! Môžem ti pomôcť s otázkami al...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>o1-preview</td>\n",
       "      <td>reka-core-20240904</td>\n",
       "      <td>Slovak</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00010ed04b536f56ebe43eef1100c13906abea12bf9855...</td>\n",
       "      <td>You will be given a piece of news. Analyze it ...</td>\n",
       "      <td>Let's break down the news and analyze it accor...</td>\n",
       "      <td>```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gemma-2-27b-it</td>\n",
       "      <td>gemini-1.5-flash-002</td>\n",
       "      <td>Russian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003800d510e38803efba5ceaec122bc66408fe367b0be...</td>\n",
       "      <td>Dört basamaklı, rakamları birbirinden ve sıfır...</td>\n",
       "      <td>Bu soruyu çözmek için, verilen koşulları adım ...</td>\n",
       "      <td>Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>gpt-4-0125-preview</td>\n",
       "      <td>claude-3-5-sonnet-20240620</td>\n",
       "      <td>Turkish</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00072026c68f5418ef2da238394e418ce72a534b9b22d5...</td>\n",
       "      <td>현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...</td>\n",
       "      <td>죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...</td>\n",
       "      <td>현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...</td>\n",
       "      <td>model_b</td>\n",
       "      <td>gemma-2-2b-it</td>\n",
       "      <td>llama-3.1-nemotron-70b-instruct</td>\n",
       "      <td>English</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...</td>\n",
       "      <td>Please be boring</td>\n",
       "      <td>Alright, I'll be as boring as possible.\\n\\nTod...</td>\n",
       "      <td>Understood. Here is a straightforward, unadorn...</td>\n",
       "      <td>model_a</td>\n",
       "      <td>reka-flash-20240722</td>\n",
       "      <td>grok-2-2024-08-13</td>\n",
       "      <td>English</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  00007cff95d7f7974642a785aca248b0f26e60d3312fac...   \n",
       "1  00010ed04b536f56ebe43eef1100c13906abea12bf9855...   \n",
       "2  0003800d510e38803efba5ceaec122bc66408fe367b0be...   \n",
       "3  00072026c68f5418ef2da238394e418ce72a534b9b22d5...   \n",
       "4  0007ce7cf6bc1b5a8f8a4669b854fb12030863c970d9dc...   \n",
       "\n",
       "                                              prompt  \\\n",
       "0                                 vieš po Slovensky?   \n",
       "1  You will be given a piece of news. Analyze it ...   \n",
       "2  Dört basamaklı, rakamları birbirinden ve sıfır...   \n",
       "3  현재 추천된 탑 3 종목인 Cabaletta Bio (CABA), Rocket Ph...   \n",
       "4                                  Please be boring    \n",
       "\n",
       "                                          response_a  \\\n",
       "0   Áno, hovorím po slovensky. Ako vám môžem pomôcť?   \n",
       "1  Let's break down the news and analyze it accor...   \n",
       "2  Bu soruyu çözmek için, verilen koşulları adım ...   \n",
       "3  죄송하지만 저는 금융 조언을 제공할 수 없습니다. 저는 AI 모델이며, 투자 결정에...   \n",
       "4  Alright, I'll be as boring as possible.\\n\\nTod...   \n",
       "\n",
       "                                          response_b   winner  \\\n",
       "0  Áno, veď som tu! Môžem ti pomôcť s otázkami al...  model_a   \n",
       "1  ```json\\n{\\n  \"contains_orgs\": true,\\n  \"orgs\"...  model_a   \n",
       "2  Bu problemi adım adım çözelim:\\n\\n1) ABCD - DC...  model_a   \n",
       "3  현재 추천된 탑 3 종목에 순위를 매기기 위해서는 여러 가지 요소들을 고려해야 합니...  model_b   \n",
       "4  Understood. Here is a straightforward, unadorn...  model_a   \n",
       "\n",
       "               model_a                          model_b language  \\\n",
       "0           o1-preview               reka-core-20240904   Slovak   \n",
       "1       gemma-2-27b-it             gemini-1.5-flash-002  Russian   \n",
       "2   gpt-4-0125-preview       claude-3-5-sonnet-20240620  Turkish   \n",
       "3        gemma-2-2b-it  llama-3.1-nemotron-70b-instruct  English   \n",
       "4  reka-flash-20240722                grok-2-2024-08-13  English   \n",
       "\n",
       "   winner_model_a  winner_model_b  \n",
       "0               1               0  \n",
       "1               1               0  \n",
       "2               1               0  \n",
       "3               0               1  \n",
       "4               1               0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:51.264543Z",
     "iopub.status.busy": "2025-01-09T22:28:51.264311Z",
     "iopub.status.idle": "2025-01-09T22:28:51.284240Z",
     "shell.execute_reply": "2025-01-09T22:28:51.283567Z",
     "shell.execute_reply.started": "2025-01-09T22:28:51.264521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# raw_train_dataset[input_columns] = raw_train_dataset[input_columns].map(lambda x: eval(x)[0] if 'null' not in x else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:51.285730Z",
     "iopub.status.busy": "2025-01-09T22:28:51.285428Z",
     "iopub.status.idle": "2025-01-09T22:28:51.356265Z",
     "shell.execute_reply": "2025-01-09T22:28:51.354704Z",
     "shell.execute_reply.started": "2025-01-09T22:28:51.285708Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "raw_train_dataset = raw_train_dataset.dropna().drop(['model_a','model_b'],axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:28:51.357293Z",
     "iopub.status.busy": "2025-01-09T22:28:51.357047Z",
     "iopub.status.idle": "2025-01-09T22:29:20.258116Z",
     "shell.execute_reply": "2025-01-09T22:29:20.256407Z",
     "shell.execute_reply.started": "2025-01-09T22:28:51.357268Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.DataFrame({\n",
    "    'text': raw_train_dataset[input_columns].apply(\n",
    "        lambda row: (\n",
    "            f\"\\n\\nPROMPT:\\n\\n{row['prompt']}\\n\\n\"\n",
    "            f\"RESPONSE A:\\n\\n{row['response_a']}\\n\\n\"\n",
    "            f\"RESPONSE B:\\n\\n{row['response_b']}\\n\\n\"\n",
    "            \"TASK: select the model that gave better response model_a or model_b just output in one word\"\n",
    "        ), axis=1).apply(remove_surrogates),\n",
    "    'label': raw_train_dataset[label_columns].apply(lambda x: x.values.tolist(), axis=1)\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:29:20.259084Z",
     "iopub.status.busy": "2025-01-09T22:29:20.258823Z",
     "iopub.status.idle": "2025-01-09T22:29:20.267991Z",
     "shell.execute_reply": "2025-01-09T22:29:20.266919Z",
     "shell.execute_reply.started": "2025-01-09T22:29:20.259059Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nPROMPT:\\n\\nvieš po Slovensky?\\n\\nRESPONSE ...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\nPROMPT:\\n\\nYou will be given a piece of ne...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\nPROMPT:\\n\\nDört basamaklı, rakamları birbi...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n\\nPROMPT:\\n\\n현재 추천된 탑 3 종목인 Cabaletta Bio (C...</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n\\nPROMPT:\\n\\nPlease be boring \\n\\nRESPONSE A...</td>\n",
       "      <td>[1, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text   label\n",
       "0  \\n\\nPROMPT:\\n\\nvieš po Slovensky?\\n\\nRESPONSE ...  [1, 0]\n",
       "1  \\n\\nPROMPT:\\n\\nYou will be given a piece of ne...  [1, 0]\n",
       "2  \\n\\nPROMPT:\\n\\nDört basamaklı, rakamları birbi...  [1, 0]\n",
       "3  \\n\\nPROMPT:\\n\\n현재 추천된 탑 3 종목인 Cabaletta Bio (C...  [0, 1]\n",
       "4  \\n\\nPROMPT:\\n\\nPlease be boring \\n\\nRESPONSE A...  [1, 0]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:29:20.269257Z",
     "iopub.status.busy": "2025-01-09T22:29:20.269002Z",
     "iopub.status.idle": "2025-01-09T22:29:20.284579Z",
     "shell.execute_reply": "2025-01-09T22:29:20.283506Z",
     "shell.execute_reply.started": "2025-01-09T22:29:20.269231Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_parallel = keras.distribution.ModelParallel(\n",
    "    layout_map = layout_map,\n",
    "    batch_dim_name = \"batch\",\n",
    ")\n",
    "\n",
    "keras.distribution.set_distribution(model_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Model\n",
    "KerasNLP provides implementations of many popular model architectures. In this tutorial, you'll create a model using GemmaCausalLM, an end-to-end Gemma model for causal language modeling. A causal language model predicts the next token based on previous tokens.\n",
    "<br>\n",
    "Create the model using the from_preset method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:29:20.285741Z",
     "iopub.status.busy": "2025-01-09T22:29:20.285522Z",
     "iopub.status.idle": "2025-01-09T22:31:50.845186Z",
     "shell.execute_reply": "2025-01-09T22:31:50.843939Z",
     "shell.execute_reply.started": "2025-01-09T22:29:20.285719Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3584</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">9,241,705,984</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">917,504,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3584\u001b[0m)        │   \u001b[38;5;34m9,241,705,984\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m917,504,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,241,705,984</span> (34.43 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,241,705,984\u001b[0m (34.43 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,241,705,984</span> (34.43 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,241,705,984\u001b[0m (34.43 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"/kaggle/input/gemma2/keras/gemma2_instruct_9b_en/3\")\n",
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LoRA Fine-tuning\n",
    "- To get better responses from the model, fine-tune the model with Low Rank Adaptation (LoRA)\n",
    "\n",
    "- The LoRA rank determines the dimensionality of the trainable matrices that are added to the original weights of the LLM. It controls the expressiveness and precision of the fine-tuning adjustments.\n",
    "\n",
    "- A higher rank means more detailed changes are possible, but also means more trainable parameters. A lower rank means less computational overhead, but potentially less precise adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:50.846702Z",
     "iopub.status.busy": "2025-01-09T22:31:50.846460Z",
     "iopub.status.idle": "2025-01-09T22:31:51.680829Z",
     "shell.execute_reply": "2025-01-09T22:31:51.679377Z",
     "shell.execute_reply.started": "2025-01-09T22:31:50.846678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "gemma_lm.backbone.enable_lora(rank = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:51.681997Z",
     "iopub.status.busy": "2025-01-09T22:31:51.681710Z",
     "iopub.status.idle": "2025-01-09T22:31:51.688934Z",
     "shell.execute_reply": "2025-01-09T22:31:51.687743Z",
     "shell.execute_reply.started": "2025-01-09T22:31:51.681956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for layer in gemma_lm._backbone.layers[:16]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:51.690379Z",
     "iopub.status.busy": "2025-01-09T22:31:51.690116Z",
     "iopub.status.idle": "2025-01-09T22:31:51.751245Z",
     "shell.execute_reply": "2025-01-09T22:31:51.750218Z",
     "shell.execute_reply.started": "2025-01-09T22:31:51.690345Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3584</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">9,299,852,800</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">917,504,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3584\u001b[0m)        │   \u001b[38;5;34m9,299,852,800\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m917,504,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,299,852,800</span> (34.64 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,299,852,800\u001b[0m (34.64 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,148,992</span> (153.16 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,148,992\u001b[0m (153.16 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,259,703,808</span> (34.50 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,259,703,808\u001b[0m (34.50 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:51.752881Z",
     "iopub.status.busy": "2025-01-09T22:31:51.752585Z",
     "iopub.status.idle": "2025-01-09T22:31:51.758030Z",
     "shell.execute_reply": "2025-01-09T22:31:51.756706Z",
     "shell.execute_reply.started": "2025-01-09T22:31:51.752856Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_fn(text, label=None):\n",
    "    preprocessed = gemma_lm._preprocessor(text, sequence_length=1024)[0]\n",
    "    # Ensure the preprocess function returns only the necessary inputs\n",
    "    return {'token_ids' : preprocessed['token_ids'], 'padding_mask' : preprocessed['padding_mask']}, label if label is not None else text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:51.759248Z",
     "iopub.status.busy": "2025-01-09T22:31:51.758960Z",
     "iopub.status.idle": "2025-01-09T22:31:52.114794Z",
     "shell.execute_reply": "2025-01-09T22:31:52.113117Z",
     "shell.execute_reply.started": "2025-01-09T22:31:51.759223Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1024, 3584)\n",
      "(None, 3584)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.layers import Input, Dense, Flatten, GlobalAveragePooling1D\n",
    "from keras import Model\n",
    "\n",
    "inputs = {\n",
    "    \"token_ids\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"token_ids\"),\n",
    "    \"padding_mask\": keras.Input(shape=(1024,), dtype=tf.int32, name=\"padding_mask\"),\n",
    "}\n",
    "x = gemma_lm.backbone(inputs)\n",
    "print(x.shape)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "print(x.shape)\n",
    "\n",
    "outputs = Dense(2, 'softmax')(x)\n",
    "model = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:52.115845Z",
     "iopub.status.busy": "2025-01-09T22:31:52.115590Z",
     "iopub.status.idle": "2025-01-09T22:31:52.123288Z",
     "shell.execute_reply": "2025-01-09T22:31:52.122071Z",
     "shell.execute_reply.started": "2025-01-09T22:31:52.115819Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.AdamW(\n",
    "                learning_rate=5e-5,\n",
    "                weight_decay=0.01,)\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:52.124760Z",
     "iopub.status.busy": "2025-01-09T22:31:52.124508Z",
     "iopub.status.idle": "2025-01-09T22:31:52.160205Z",
     "shell.execute_reply": "2025-01-09T22:31:52.159387Z",
     "shell.execute_reply.started": "2025-01-09T22:31:52.124735Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer, loss=tf.keras.losses.CategoricalCrossentropy(),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:52.161737Z",
     "iopub.status.busy": "2025-01-09T22:31:52.161521Z",
     "iopub.status.idle": "2025-01-09T22:31:52.989599Z",
     "shell.execute_reply": "2025-01-09T22:31:52.988101Z",
     "shell.execute_reply.started": "2025-01-09T22:31:52.161716Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "ds = tf.data.Dataset.from_tensor_slices((train_dataset.text.values, raw_train_dataset[label_columns].values)).batch(2).map(preprocess_fn)\n",
    "ds = ds.shuffle(ds.cardinality())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-09T22:31:52.991112Z",
     "iopub.status.busy": "2025-01-09T22:31:52.990717Z",
     "iopub.status.idle": "2025-01-10T04:27:38.156587Z",
     "shell.execute_reply": "2025-01-10T04:27:38.155277Z",
     "shell.execute_reply.started": "2025-01-09T22:31:52.991085Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m21798/21798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10666s\u001b[0m 478ms/step - loss: 0.7337 - val_loss: 0.6449\n",
      "Epoch 2/2\n",
      "\u001b[1m21798/21798\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10512s\u001b[0m 474ms/step - loss: 0.6164 - val_loss: 0.5075\n"
     ]
    }
   ],
   "source": [
    "train_split = ds.take(int(len(ds)*0.9))\n",
    "val_split = ds.skip(int(len(ds)*0.9)).take(int(len(ds)*0.1))\n",
    "histories = model.fit(train_split, validation_data=[val_split], epochs=2, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T04:27:38.159432Z",
     "iopub.status.busy": "2025-01-10T04:27:38.159127Z",
     "iopub.status.idle": "2025-01-10T04:27:38.801051Z",
     "shell.execute_reply": "2025-01-10T04:27:38.799737Z",
     "shell.execute_reply.started": "2025-01-10T04:27:38.159403Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "layer = model.get_layer(name='dense')\n",
    "weights = layer.get_weights()\n",
    "kernel, bias = weights\n",
    "\n",
    "# Save the kernel and bias separate\n",
    "np.save('dense_1_kernel.npy', kernel)\n",
    "np.save('dense_1_bias.npy', bias)\n",
    "model.layers[2].save_lora_weights(\"model.lora.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T04:27:38.837773Z",
     "iopub.status.busy": "2025-01-10T04:27:38.837524Z",
     "iopub.status.idle": "2025-01-10T04:27:38.852812Z",
     "shell.execute_reply": "2025-01-10T04:27:38.852144Z",
     "shell.execute_reply.started": "2025-01-10T04:27:38.837750Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#learning about the llm fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-10T04:27:38.854329Z",
     "iopub.status.busy": "2025-01-10T04:27:38.854052Z",
     "iopub.status.idle": "2025-01-10T04:27:38.867933Z",
     "shell.execute_reply": "2025-01-10T04:27:38.866841Z",
     "shell.execute_reply.started": "2025-01-10T04:27:38.854304Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n- the model is taking 3 hrs time for each epoch\\n- keep persistence on \\n- keep suitable number of epochs so that it dont exceed session timeout \\n\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It is observed that:\n",
    "'''\n",
    "- the model is taking 3 hrs time for each epoch\n",
    "- keep persistence on \n",
    "- keep suitable number of epochs so that it dont exceed session timeout \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Compress the /kaggle/working directory into a zip file\n",
    "shutil.make_archive('/kaggle/working/all_files', 'zip', '/kaggle/working')\n",
    "\n",
    "# Output the zip file for download\n",
    "from IPython.display import FileLink\n",
    "FileLink('/kaggle/working/all_files.zip')\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 78150,
     "modelInstanceId": 57466,
     "sourceId": 205104,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
