{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea144003",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-07T12:50:29.556961Z",
     "iopub.status.busy": "2025-01-07T12:50:29.556695Z",
     "iopub.status.idle": "2025-01-07T12:50:30.108279Z",
     "shell.execute_reply": "2025-01-07T12:50:30.107259Z"
    },
    "papermill": {
     "duration": 0.556336,
     "end_time": "2025-01-07T12:50:30.109868",
     "exception": false,
     "start_time": "2025-01-07T12:50:29.553532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model.safetensors.index.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00003-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/LICENSE\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00001-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/README.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/USE_POLICY.md\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/tokenizer_config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00004-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/special_tokens_map.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/.gitattributes\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/model-00002-of-00004.safetensors\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/generation_config.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/consolidated.00.pth\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/params.json\n",
      "/kaggle/input/llama-3.1/transformers/8b-instruct/2/original/tokenizer.model\n",
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/sample_submission.csv\n",
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet\n",
      "/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344f3ddb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T12:50:30.114981Z",
     "iopub.status.busy": "2025-01-07T12:50:30.114649Z",
     "iopub.status.idle": "2025-01-07T12:50:43.379156Z",
     "shell.execute_reply": "2025-01-07T12:50:43.378174Z"
    },
    "papermill": {
     "duration": 13.26851,
     "end_time": "2025-01-07T12:50:43.380772",
     "exception": false,
     "start_time": "2025-01-07T12:50:30.112262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df3b65c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T12:50:43.386322Z",
     "iopub.status.busy": "2025-01-07T12:50:43.385774Z",
     "iopub.status.idle": "2025-01-07T12:54:09.807606Z",
     "shell.execute_reply": "2025-01-07T12:54:09.806797Z"
    },
    "papermill": {
     "duration": 206.426477,
     "end_time": "2025-01-07T12:54:09.809484",
     "exception": false,
     "start_time": "2025-01-07T12:50:43.383007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de162c7610b44fc1825657c85bb7a17c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_id = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
    "# Load the test dataset\n",
    "test_data = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n",
    "\n",
    "messages_pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "# Prepare messages for prediction\n",
    "def prepare_message(row):\n",
    "    return (\n",
    "        \"Choose the better response. Answer with 'model_a' or 'model_b'. \"\n",
    "        \"Only provide one word as your answer.\\n\\nInstruction:\\n\"\n",
    "        \"Given the following responses to the prompt, choose which one is better.\\n\\n\"\n",
    "        f\"Input:\\n{row['prompt']}\\n\\n\"\n",
    "        f\"Response A:\\n{row['response_a']}\\n\\n\"\n",
    "        f\"Response B:\\n{row['response_b']}\\n\\n\"\n",
    "        \"Which response is better?\\nmodel_a or model_b\\n\\nAnswer with only one word.\"\n",
    "    )\n",
    "\n",
    "\n",
    "# Predict for each row in the test dataset\n",
    "predictions = []\n",
    "for _, row in test_data.iterrows():\n",
    "    messages = prepare_message(row)\n",
    "    output = messages_pipeline(messages, max_new_tokens=256)\n",
    "    \n",
    "    # Extract generated text and handle it properly\n",
    "    if isinstance(output, list) and \"generated_text\" in output[0]:\n",
    "        generated_text = output[0][\"generated_text\"].strip().lower()  # Normalize\n",
    "        prediction = \"model_a\" if \"model_a\" in generated_text else \"model_b\"\n",
    "    else:\n",
    "        prediction = \"model_b\"  # Default fallback\n",
    "\n",
    "    \n",
    "    # Ensure valid prediction\n",
    "    if prediction not in [\"model_a\", \"model_b\"]:\n",
    "        prediction = \"model_a\"  # Fallback for invalid predictions\n",
    "    \n",
    "    predictions.append({\"id\": row['id'], \"winner\": prediction})\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "submission = pd.DataFrame(predictions)\n",
    "\n",
    "# Save to a CSV file in the required submission format\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8813eaf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T12:54:09.815369Z",
     "iopub.status.busy": "2025-01-07T12:54:09.815138Z",
     "iopub.status.idle": "2025-01-07T12:54:09.827594Z",
     "shell.execute_reply": "2025-01-07T12:54:09.826758Z"
    },
    "papermill": {
     "duration": 0.01667,
     "end_time": "2025-01-07T12:54:09.828892",
     "exception": false,
     "start_time": "2025-01-07T12:54:09.812222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>327228</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1139415</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1235630</td>\n",
       "      <td>model_a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id   winner\n",
       "0   327228  model_a\n",
       "1  1139415  model_a\n",
       "2  1235630  model_a"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "view = pd.read_csv('/kaggle/working/submission.csv')\n",
    "view.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf02906",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T12:54:09.834025Z",
     "iopub.status.busy": "2025-01-07T12:54:09.833817Z",
     "iopub.status.idle": "2025-01-07T12:54:09.837216Z",
     "shell.execute_reply": "2025-01-07T12:54:09.836572Z"
    },
    "papermill": {
     "duration": 0.007278,
     "end_time": "2025-01-07T12:54:09.838452",
     "exception": false,
     "start_time": "2025-01-07T12:54:09.831174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Load and preprocess dataset\n",
    "# train_data = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/train.parquet')\n",
    "\n",
    "# # Prepare data for training\n",
    "# def prepare_data(row):\n",
    "#     return {\n",
    "#         \"prompt\": row[\"prompt\"],\n",
    "#         \"response_a\": row[\"response_a\"],\n",
    "#         \"response_b\": row[\"response_b\"],\n",
    "#         \"winner\": row[\"winner\"]  # Use this if it's needed for labels\n",
    "#     }\n",
    "\n",
    "# train_data_prepared = train_data.apply(prepare_data, axis=1).tolist()\n",
    "# train_dataset = Dataset.from_pandas(pd.DataFrame(train_data_prepared))\n",
    "\n",
    "# # Define tokenizer and model\n",
    "# model_name = \"/kaggle/input/llama-3.1/transformers/8b-instruct/2\"\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# # Enable gradient checkpointing to save memory\n",
    "# model.gradient_checkpointing_enable()\n",
    "\n",
    "# # Tokenize dataset with smaller max length\n",
    "# def preprocess_data(example):\n",
    "#     return tokenizer(example['prompt'], text_pair=example['response_a'], truncation=True, max_length=256)  # Lower max_length\n",
    "\n",
    "# tokenized_dataset = train_dataset.map(preprocess_data, batched=True)\n",
    "\n",
    "# # Fine-tuning configurations with multi-GPU setup\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir=\"./results\",\n",
    "#     evaluation_strategy=\"steps\",\n",
    "#     save_steps=500,\n",
    "#     per_device_train_batch_size=1,  # Lower batch size\n",
    "#     per_device_eval_batch_size=1,\n",
    "#     num_train_epochs=1,\n",
    "#     learning_rate=1e-3,\n",
    "#     save_total_limit=2,\n",
    "#     logging_dir=\"./logs\",\n",
    "#     logging_steps=100,\n",
    "#     fp16=True,  # Use mixed precision for faster training\n",
    "#     device_map=\"auto\",  # Automatically use available GPUs\n",
    "# )\n",
    "\n",
    "# # Setup the Trainer with the multi-GPU configuration\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=tokenized_dataset,\n",
    "# )\n",
    "\n",
    "# # Train model\n",
    "# trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b556fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-07T12:54:09.843521Z",
     "iopub.status.busy": "2025-01-07T12:54:09.843314Z",
     "iopub.status.idle": "2025-01-07T12:54:09.846307Z",
     "shell.execute_reply": "2025-01-07T12:54:09.845640Z"
    },
    "papermill": {
     "duration": 0.006879,
     "end_time": "2025-01-07T12:54:09.847527",
     "exception": false,
     "start_time": "2025-01-07T12:54:09.840648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # After training, perform inference directly with the trained model\n",
    "# messages_pipeline = pipeline(\n",
    "#     \"text-generation\",\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "#     device_map=\"auto\",  # This ensures it's running on the available GPU (if applicable)\n",
    "# )\n",
    "\n",
    "# # Load the test dataset\n",
    "# test_data = pd.read_parquet('/kaggle/input/wsdm-cup-multilingual-chatbot-arena/test.parquet')\n",
    "\n",
    "# # Prepare messages for prediction\n",
    "# def prepare_message(row):\n",
    "#     return [\n",
    "#         {\"role\": \"system\", \"content\": \"Choose the better response. Answer with 'model_a' or 'model_b'. Only provide one word as your answer.\\n\\nInstruction:\\nGiven the following responses to the prompt, choose which one is better.\\n\\nInput:\\n\" \n",
    "#          + row['prompt'] +\n",
    "#          \"\\n\\nResponse A:\\n\" + row['response_a'] +\n",
    "#          \"\\n\\nResponse B:\\n\" + row['response_b'] +\n",
    "#          \"\\n\\nWhich response is better?\\nmodel_a or model_b\\n\\nAnswer with only one word.\"}\n",
    "#     ]\n",
    "\n",
    "# # Predict for each row in the test dataset\n",
    "# predictions = []\n",
    "# for _, row in test_data.iterrows():\n",
    "#     messages = prepare_message(row)\n",
    "#     output = messages_pipeline(messages, max_new_tokens=256)\n",
    "    \n",
    "#     # Extract generated text and handle it properly\n",
    "#     if isinstance(output, list) and \"generated_text\" in output[0]:\n",
    "#         prediction = output[0][\"generated_text\"][-1]  # Extract the last character to determine model_a or model_b\n",
    "#     else:\n",
    "#         prediction = \"model_a\"  # Fallback to model_a if the output is unexpected\n",
    "    \n",
    "#     # Ensure valid prediction\n",
    "#     if prediction not in [\"model_a\", \"model_b\"]:\n",
    "#         prediction = \"model_a\"  # Fallback for invalid predictions\n",
    "    \n",
    "#     predictions.append({\"id\": row['id'], \"winner\": prediction})\n",
    "#     print(f\"Prediction completed for id {row['id']}\")\n",
    "\n",
    "# # Convert predictions to a DataFrame\n",
    "# submission = pd.DataFrame(predictions)\n",
    "\n",
    "# # Save to a CSV file in the required submission format\n",
    "# submission.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 10131489,
     "sourceId": 86946,
     "sourceType": "competition"
    },
    {
     "modelId": 91102,
     "modelInstanceId": 68809,
     "sourceId": 104449,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 225.740339,
   "end_time": "2025-01-07T12:54:13.267135",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-07T12:50:27.526796",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "09a46a33b2824b73b5ef9c4698d901e4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0a369ce46cd3498c983cf31edff6d3f9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f9b75bf36dd54f8ab22c3529ebf7f79d",
       "placeholder": "​",
       "style": "IPY_MODEL_eb300580f1e047acbdc6cb8e7740a828",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "3201f015029d498a8e6bd49579e13346": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "827998d0ea584f168fb1cf5be0dbb52b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_09a46a33b2824b73b5ef9c4698d901e4",
       "max": 4.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_842e2a55cbaa474197e00c152558c6dc",
       "tabbable": null,
       "tooltip": null,
       "value": 4.0
      }
     },
     "842e2a55cbaa474197e00c152558c6dc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "860bcfecfc0c41c190690625f33ecc83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3201f015029d498a8e6bd49579e13346",
       "placeholder": "​",
       "style": "IPY_MODEL_d7580b3d3b9d4bca97a4d6b74da2be28",
       "tabbable": null,
       "tooltip": null,
       "value": " 4/4 [01:57&lt;00:00, 25.61s/it]"
      }
     },
     "badcf5fb22254719895e48206b4258fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d7580b3d3b9d4bca97a4d6b74da2be28": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "de162c7610b44fc1825657c85bb7a17c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0a369ce46cd3498c983cf31edff6d3f9",
        "IPY_MODEL_827998d0ea584f168fb1cf5be0dbb52b",
        "IPY_MODEL_860bcfecfc0c41c190690625f33ecc83"
       ],
       "layout": "IPY_MODEL_badcf5fb22254719895e48206b4258fd",
       "tabbable": null,
       "tooltip": null
      }
     },
     "eb300580f1e047acbdc6cb8e7740a828": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f9b75bf36dd54f8ab22c3529ebf7f79d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
